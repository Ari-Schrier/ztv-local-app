from moviepy.editor import *
from AI.aiFunctions import getSpeech
import json
import random

VOICE_ACTOR= "echo"

def getAudioFor(title, question):
    destination = f"output/{title}/{question["id"]}_"
    for each in ["question", "fun fact"]:
        getSpeech(destination+each+".mp3", question[each], VOICE_ACTOR)
    for each in ["A", "B", "C", "D"]:
        getSpeech(destination+each+".mp3", question[each][2:] +"?", VOICE_ACTOR)
    answer = question["answer"]
    getSpeech(destination+"answer.mp3", f"The answer is {answer}: {question[answer][2:]}.")

def combine_videos_with_transition(clips, transition_duration):
    return concatenate_videoclips([
            clip if i == 0 else clip.crossfadein(transition_duration)
            for i, clip in enumerate(clips)
        ],
        padding=-transition_duration, 
        method="compose"
    )

def ken_burns_effect(image_path, duration, zoom_start=1.0, zoom_end=1.4):
    clip = ImageClip(image_path)
    w, h = clip.size
    
    # Randomly choose a corner: 'top-left', 'top-right', 'bottom-left', 'bottom-right'
    corners = ['top-left', 'top-right', 'bottom-left', 'bottom-right']
    chosen_corner = random.choice(corners)
    
    def get_crop_center(chosen_corner, w, h, zoom):
        if chosen_corner == 'top-left':
            return w / (2 * zoom), h / (2 * zoom)
        elif chosen_corner == 'top-right':
            return w - w / (2 * zoom), h / (2 * zoom)
        elif chosen_corner == 'bottom-left':
            return w / (2 * zoom), h - h / (2 * zoom)
        elif chosen_corner == 'bottom-right':
            return w - w / (2 * zoom), h - h / (2 * zoom)
    
    def make_frame(t):
        zoom = zoom_start + (zoom_end - zoom_start) * (t / duration)
        x_center, y_center = get_crop_center(chosen_corner, w, h, zoom)
        cropped = clip.crop(x_center=x_center, y_center=y_center, width=w/zoom, height=h/zoom)
        return cropped.resize((w, h)).get_frame(t)
    
    return VideoClip(make_frame, duration=duration)

def add_caption(clip, text, fontsize=75, font='Arial', margin=120, y_offset=50):
    
    # Create the text clip with a fixed font size and wrapping
    txt_clip = TextClip(text, fontsize=fontsize, bg_color='black', color='white', font=font, method='caption', interline=10, size=(clip.w - 2 * margin, None)).set_duration(clip.duration)
    
    # Determine the position for the text and background
    txt_clip = txt_clip.set_position(('center', 'bottom'))

    # Make the clip partially transparent
    txt_clip = txt_clip.set_opacity(.7)
    
    # Move the clip up by y_offset pixels
    final_clip = CompositeVideoClip([clip, txt_clip.set_position(('center', clip.h - txt_clip.h - y_offset))])
    
    return final_clip

def addLogo(video):

    # Load the watermark image
    watermark = ImageClip("resources/logo.png")

    # Resize the watermark if needed
    watermark = watermark.resize(height=50)  # Adjust the height to your needs

    # Set the position of the watermark (top-left corner)
    watermark = watermark.set_position((70, 85))

    watermark = watermark.set_opacity(.5)

    # Set the duration of the watermark to match the video duration
    watermark = watermark.set_duration(video.duration)

    # Composite the video and the watermark
    final_video = CompositeVideoClip([video, watermark])

    return final_video

def makeTitle(text, size, duration=8):
    bg = ColorClip(size=size, color=(0, 0, 0), duration=duration)

    # Create a text clip with the desired caption, specify the width for wrapping
    caption = text
    title_text = TextClip(caption, font="resources/HelveticaNeueBold.otf", method="caption", align="west", fontsize=160, color='white', size=(size[0] - 800, None))
    title_text = title_text.set_duration(duration)

    # Calculate the position: centered on y-axis and 150 pixels from the left edge
    x_pos = 120
    y_pos = (1080 - title_text.size[1]) / 2

    # Apply the calculated position to the text clip
    title_text = title_text.set_pos((x_pos, y_pos))

    # Composite the text clip on top of the black screen
    return CompositeVideoClip(clips=[bg, title_text])

def makeQuizChunk(title, question, current_answer):
    size = (1920, 1080)
    vertical_padding = 7
    answers = ["A", "B", "C", "D"]
    duration = 4
    audio = None
    if current_answer is not None:
        try:
            audio_path = f"output/{title}/{question['id']}_{current_answer}.mp3"
            audio = AudioFileClip(audio_path)
            silence = AudioFileClip("resources/15-seconds-of-silence.mp3")
            duration = max(6, (audio.duration + 4))
            audio = concatenate_audioclips([silence.subclip(0, 1), audio, silence])
        except OSError as e:
            print(f"Error loading audio file: {e}")
            audio = None
    
    bg = ColorClip(size=size, color=(0, 0, 0), duration=duration)
    question_text = TextClip(
        question['question'], 
        font="resources/HelveticaNeueBold.otf", 
        method="caption", 
        align="west", 
        fontsize=80, 
        color='white', 
        kerning=5, 
        size=(size[0] - 800, None)
    ).set_pos((120, 200)).set_duration(duration)
    
    clips = [bg, question_text]
    new_line = 220 + question_text.size[1]
    
    for answer in answers:
        text_color = "black" if answer == current_answer else "white"
        bg_color = "red" if answer == current_answer else "transparent"
        
        # Create a background color clip for the margin
        margin_bg = ColorClip(
            size=(size[0] - 800, 75 + vertical_padding), 
            color=(255, 0, 0) if answer == current_answer else (0, 0, 0, 0),
            duration=duration
        ).set_pos((150, new_line - vertical_padding))
        
        new_text = TextClip(
            question[answer], 
            font="resources/HelveticaNeueThin.otf", 
            method="caption", 
            align="west", 
            fontsize=75, 
            color=text_color, 
            kerning=5, 
            size=(size[0] - 800, None)
        ).set_duration(duration).set_pos((150, new_line))
        
        new_line += (vertical_padding + new_text.size[1] + 25)
        clips.append(margin_bg)
        clips.append(new_text)
    
    fullClip = CompositeVideoClip(clips).set_duration(duration)  # Ensure fullClip duration is set to DURATION

    if audio:
        audio = audio.set_duration(fullClip.duration)
        fullClip = fullClip.set_audio(audio)

    return fullClip

def makeQuizQuestion(title, question):
    chunks = ["question", "A", "B", "C", "D", "answer"]  # Adjust chunks as needed
    processed = [makeQuizChunk(title, question, each) for each in chunks]

    duration = 7
    audio = None
    try:
        audio_path = f"output/{title}/{question['id']}_fun fact.mp3"
        audio = AudioFileClip(audio_path)
        duration = max(8, audio.duration+5)
        silence = AudioFileClip("resources/15-seconds-of-silence.mp3")
        audio = concatenate_audioclips([silence.subclip(0, 1), audio, silence])
    except OSError as e:
        print(f"Error loading audio file: {e}")
        audio = None
    image = ken_burns_effect(f"output/{title}/{question["id"]}_image.png", duration)
    if audio:
        audio = audio.set_duration(image.duration)
        image = image.set_audio(audio)
    processed.append(image)

    return combine_videos_with_transition(processed, 1)

def make_quiz(title):
    with open(f"output/{title}/{title}.json", "r") as file:
        quiz = json.load(file)
    bigness = (1920, 1080)

    # questions = []
    # for each in quiz:
    #     question = makeQuizQuestion(title, each)
    #     questions.append(question)
    questions = [
        VideoFileClip("output/Rabbits/bit0.mp4"),
        VideoFileClip("output/Rabbits/bit1.mp4"),
        VideoFileClip("output/Rabbits/bit2.mp4"),
        VideoFileClip("output/Rabbits/bit3.mp4"),
        VideoFileClip("output/Rabbits/bit4.mp4")
    ]

    quiz = combine_videos_with_transition(questions, 1)

    # title = makeTitle(title, bigness, duration=5)
    # title.write_videofile("output/Rabbits/title.mp4", fps=24)
    title = VideoFileClip("output/Rabbits/title.mp4")
    myClip = concatenate_videoclips([title, quiz], method='compose')
    myClip = addLogo(myClip)
    end_card = VideoFileClip("resources/endcredits.m4v").resize(myClip.size)
    myClip = concatenate_videoclips([myClip, end_card], method='compose')

    myClip.write_videofile(f'output/{title}/{title}.mp4', fps=24)

def finish_quiz(title, clipLocations):
    
    try:
        # Process the quiz questions
        questions = [VideoFileClip(each) for each in clipLocations]

        # Combine questions with transitions
        my_clip = combine_videos_with_transition(questions, 1)
    except Exception as e:
        print(f"Error combining videos: {e}")
        return

    try:
        # Add logo
        my_clip = addLogo(my_clip)
    except Exception as e:
        print(f"Error adding logo: {e}")
        return
    
    try:
        # Add end card
        end_card = VideoFileClip("resources/endcredits.m4v").resize(my_clip.size)
        my_clip = combine_videos_with_transition([my_clip, end_card], 1)
    except Exception as e:
        print(f"Error adding end card: {e}")
        return
    
    try:
        # Write final video file
        output_path = f'output/{title}/{title}_complete.mp4'
        my_clip.write_videofile(output_path, fps=24)
        print(f"Successfully created video: {output_path}")
    except Exception as e:
        print(f"Error writing video file: {e}")

def preprocess_video(title):
    with open(f"output/{title}/{title}.json", "r") as file:
        quiz = json.load(file)
    my_title = makeTitle(title, (1920, 1080))
    title_path = f"output/{title}/title.mp4"
    my_title.write_videofile(title_path)
    clips = [title_path]
    for each in quiz:
        getAudioFor(title, each)
        question = makeQuizQuestion(title, each)
        output_path = f'output/{title}/{title}_partial.mp4'
        question.write_videofile(output_path, fps=24)
        clips.append(output_path)
    return clips

if __name__ == "__main__":
    making = "x"
    partial = preprocess_video(making)
    finish_quiz(making, partial)
